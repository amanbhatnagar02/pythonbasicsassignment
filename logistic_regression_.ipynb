{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Question 1: What is Logistic Regression, and how does it differ from Linear Regression?"
      ],
      "metadata": {
        "id": "W70NrPSGG3S-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ans : Logistic Regression is a statistical method used for binary classification problems that predicts the probability of an instance belonging to a particular category.\n",
        "Key Differences:\n",
        "\n",
        "Output: Linear Regression predicts continuous values; Logistic Regression predicts probabilities (0-1)\n",
        "Function: Linear uses straight line; Logistic uses sigmoid curve\n",
        "Purpose: Linear for regression; Logistic for classification\n",
        "Range: Linear output can be any real number; Logistic output is bounded between 0 and 1"
      ],
      "metadata": {
        "id": "_GyrwE7wImZt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 2:  Mathematical Equation of Logistic Regression"
      ],
      "metadata": {
        "id": "7sOc9tf7HBau"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ans : The logistic regression equation is:\n",
        "p = 1 / (1 + e^(-z))\n",
        "where z = β₀ + β₁x₁ + β₂x₂ + ... + βₙxₙ\n",
        "\n",
        "p = probability of positive class\n",
        "z = linear combination of features\n",
        "β = coefficients/weights\n",
        "e = Euler's number (2.718...)"
      ],
      "metadata": {
        "id": "5oc8hNISKsb1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 3:  Why do we use the Sigmoid function in Logistic Regression?"
      ],
      "metadata": {
        "id": "nc4vND0wHBfI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ans: Reasons for Sigmoid Function:\n",
        "\n",
        "Maps any real number to a value between 0 and 1 (perfect for probabilities)\n",
        "S-shaped curve provides smooth transition\n",
        "Mathematically differentiable (needed for gradient descent)\n",
        "Provides non-linear decision boundary\n",
        "Output can be interpreted as probability"
      ],
      "metadata": {
        "id": "-7R_-YI9KtIn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 4: Cost Function of Logistic Regression"
      ],
      "metadata": {
        "id": "-UgMAgXWHBiN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ans: Log-Likelihood Cost Function:\n",
        "J(θ) = -1/m * Σ[y*log(hθ(x)) + (1-y)*log(1-hθ(x))]\n",
        "Where:\n",
        "\n",
        "m = number of training examples\n",
        "y = actual label (0 or 1)\n",
        "hθ(x) = predicted probability\n",
        "This is convex, ensuring global minimum"
      ],
      "metadata": {
        "id": "AOs-NpNnKt4y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 5:  Regularization in Logistic Regression"
      ],
      "metadata": {
        "id": "H1tghwpqHBmS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ans: Regularization adds a penalty term to prevent overfitting by constraining model complexity.\n",
        "Why needed:\n",
        "\n",
        "Prevents overfitting on training data\n",
        "Reduces model variance\n",
        "Improves generalization\n",
        "Handles multicollinearity"
      ],
      "metadata": {
        "id": "EUM4vAYzKuY0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 6:   Difference between Lasso, Ridge, and Elastic Net"
      ],
      "metadata": {
        "id": "gY34Y9NNHBoK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ans: Lasso (L1): Shrinks some coefficients to 0 (good for feature selection).\n",
        "\n",
        "Ridge (L2): Shrinks all coefficients but none to 0.\n",
        "\n",
        "Elastic Net: Mix of both L1 and L2.\n",
        "\n"
      ],
      "metadata": {
        "id": "BYZK2P32cqBB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 7:   When to use Elastic Net instead of Lasso or Ridge"
      ],
      "metadata": {
        "id": "Nw85dFDSHBq7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ans: When you have many correlated features and you want both shrinkage and feature selection"
      ],
      "metadata": {
        "id": "T1zZXnLOKvhv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 8:  What is the impact of the regularization parameter (λ) in Logistic Regression"
      ],
      "metadata": {
        "id": "TRn0IecWHBt5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ans: Impact of λ (lambda) in Logistic Regression:\n",
        "λ is the regularization strength.\n",
        "\n",
        "High λ → More regularization → Simpler model\n",
        "\n",
        "Low λ → Less regularization → More complex model"
      ],
      "metadata": {
        "id": "ZByFNyc9KxaD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 9:   What are the key assumptions of Logistic Regression"
      ],
      "metadata": {
        "id": "jJ3g6uEqHBwv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ans: Key assumptions of Logistic Regression:\n",
        "No multicollinearity\n",
        "\n",
        "Linearity between independent variables and log-odds\n",
        "\n",
        "Large sample size\n",
        "\n",
        "Independence of observations"
      ],
      "metadata": {
        "id": "dk_PaGwFdjV5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 10:  What are some alternatives to Logistic Regression for classification tasks"
      ],
      "metadata": {
        "id": "fEfIUeoXHBzm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ans: Alternatives to Logistic Regression:\n",
        "Decision Trees\n",
        "\n",
        "Random Forest\n",
        "\n",
        "SVM\n",
        "\n",
        "Naive Bayes\n",
        "\n",
        "Neural Networks"
      ],
      "metadata": {
        "id": "ZgeuAPfPKyeQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 11: What are Classification Evaluation Metrics"
      ],
      "metadata": {
        "id": "FvWhSmoLHB2f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Classification Evaluation Metrics:\n",
        "Accuracy\n",
        "\n",
        "Precision\n",
        "\n",
        "Recall\n",
        "\n",
        "F1-Score\n",
        "\n",
        "ROC-AUC\n",
        "\n",
        "Confusion Matrix\n",
        "\n",
        "Matthews Correlation Coefficient"
      ],
      "metadata": {
        "id": "gJd3OEnQKzT6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 12:  How does class imbalance affect Logistic Regression"
      ],
      "metadata": {
        "id": "O3mQxYoZH1V9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ans:  Effect of class imbalance:\n",
        "Logistic Regression might be biased toward the majority class.\n",
        "\n",
        "You can solve it using class weights or resampling."
      ],
      "metadata": {
        "id": "sQM3q1hNK0Em"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 13:  What is Hyperparameter Tuning in Logistic Regression"
      ],
      "metadata": {
        "id": "INYlelSpH1cS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ans: Hyperparameter Tuning in Logistic Regression:\n",
        "Adjusting parameters like C, penalty, and solver using GridSearchCV or RandomizedSearchCV to get best performance"
      ],
      "metadata": {
        "id": "WrAw_ifrK0tf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 14:   What are different solvers in Logistic Regression? Which one should be used"
      ],
      "metadata": {
        "id": "bPKUi6bsH1i0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ans: Different solvers in Logistic Regression:\n",
        "liblinear: small datasets, L1 or L2\n",
        "\n",
        "saga: large datasets, supports Elastic Net\n",
        "\n",
        "lbfgs: good for multiclass, default in sklearn"
      ],
      "metadata": {
        "id": "74UGKJ0uK1vX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 15:  How is Logistic Regression extended for multiclass classification"
      ],
      "metadata": {
        "id": "8Fjl9ZPSH2F-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ans: Logistic Regression for Multiclass:\n",
        "One-vs-Rest (OvR)\n",
        "\n",
        "Softmax (Multinomial)"
      ],
      "metadata": {
        "id": "qKG2PpA6K2Mi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 16:  What are the advantages and disadvantages of Logistic Regression"
      ],
      "metadata": {
        "id": "mKK73iuRH2Jw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ans:  Advantages and Disadvantages:\n",
        "✅ Simple, interpretable, fast\n",
        "\n",
        "❌ Doesn't handle non-linear data well"
      ],
      "metadata": {
        "id": "F3mxbuerK26X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 17:  What are some use cases of Logistic Regression"
      ],
      "metadata": {
        "id": "09FXfglCH2M-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ans:  Use Cases:\n",
        "Email Spam Detection\n",
        "\n",
        "Credit Card Fraud\n",
        "\n",
        "Disease Diagnosis\n",
        "\n",
        "Customer Churn Prediction"
      ],
      "metadata": {
        "id": "4kD7tph5K3Yk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 18:  What is the difference between Softmax Regression and Logistic Regression"
      ],
      "metadata": {
        "id": "Cvxj8lEIH2Te"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ans: Softmax vs Logistic Regression:\n",
        "Softmax: For multiclass classification (more than 2 classes)\n",
        "\n",
        "Logistic Regression: For binary classification (2 classes)"
      ],
      "metadata": {
        "id": "WoitpyJlK4U-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 19: How do we choose between One-vs-Rest (OvR) and Softmax for multiclass classification"
      ],
      "metadata": {
        "id": "h8p5gt4oIDle"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ans:Choosing OvR vs Softmax:\n",
        "OvR: Preferred for binary or unbalanced classes\n",
        "\n",
        "Softmax: Best for balanced multiclass classification\n",
        "\n"
      ],
      "metadata": {
        "id": "2kCx_UmDK5F8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 20:  How do we interpret coefficients in Logistic Regression?"
      ],
      "metadata": {
        "id": "C4_pAEo5IHH3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ans :  Interpreting coefficients:\n",
        "A positive coefficient increases the log-odds of the positive class.\n",
        "\n",
        "You can exponentiate it to get odds ratio.\n",
        "\n"
      ],
      "metadata": {
        "id": "f3ilDbaZK8KB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Practicle questions"
      ],
      "metadata": {
        "id": "WBY4UREOihhd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 1 :   Write a Python program that loads a dataset, splits it into training and testing sets, applies Logistic Regression, and prints the model accuracy"
      ],
      "metadata": {
        "id": "4GJ0N1hDikkf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = (data.target == 0).astype(int)  # Convert to binary classification (class 0 vs rest)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Model training\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Prediction\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Model Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPnwre2AdMlb",
        "outputId": "d15e0ffd-aaa4-449a-da4f-807979acd648"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 2 : Write a Python program to apply L1 regularization (Lasso) on a dataset using LogisticRegression(penalty='l1') and print the model accuracy"
      ],
      "metadata": {
        "id": "Lq66ReOyiolB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Logistic Regression with L1 regularization\n",
        "model = LogisticRegression(penalty='l1', solver='liblinear', max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Prediction\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Model Accuracy with L1 Regularization:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dI1zkiZDdcxV",
        "outputId": "9fa7f78e-35b5-4d99-b85b-beb7641bd981"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy with L1 Regularization: 0.956140350877193\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 3 :  Write a Python program to train Logistic Regression with L2 regularization (Ridge) using LogisticRegression(penalty='l2'). Print model accuracy and coefficients"
      ],
      "metadata": {
        "id": "jil8hKw2iopE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Logistic Regression with L2 regularization\n",
        "model = LogisticRegression(penalty='l2', solver='liblinear', max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Prediction\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Output\n",
        "print(\"Model Accuracy with L2 Regularization:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Model Coefficients:\")\n",
        "print(model.coef_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28e8tkGkdldG",
        "outputId": "76551c25-0967-4e04-ff06-75ac772d71b3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy with L2 Regularization: 0.956140350877193\n",
            "Model Coefficients:\n",
            "[[ 2.13248406e+00  1.52771940e-01 -1.45091255e-01 -8.28669349e-04\n",
            "  -1.42636015e-01 -4.15568847e-01 -6.51940282e-01 -3.44456106e-01\n",
            "  -2.07613380e-01 -2.97739324e-02 -5.00338038e-02  1.44298427e+00\n",
            "  -3.03857384e-01 -7.25692126e-02 -1.61591524e-02 -1.90655332e-03\n",
            "  -4.48855442e-02 -3.77188737e-02 -4.17516190e-02  5.61347410e-03\n",
            "   1.23214996e+00 -4.04581097e-01 -3.62091502e-02 -2.70867580e-02\n",
            "  -2.62630530e-01 -1.20898539e+00 -1.61796947e+00 -6.15250835e-01\n",
            "  -7.42763610e-01 -1.16960181e-01]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 4 :  Write a Python program to train Logistic Regression with Elastic Net Regularization (penalty='elasticnet')"
      ],
      "metadata": {
        "id": "CYlyyjTQior9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Logistic Regression with Elastic Net regularization\n",
        "model = LogisticRegression(\n",
        "    penalty='elasticnet',\n",
        "    solver='saga',\n",
        "    l1_ratio=0.5,         # Mix of L1 and L2 (0 = Ridge, 1 = Lasso)\n",
        "    max_iter=1000\n",
        ")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Prediction\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Accuracy\n",
        "print(\"Model Accuracy with Elastic Net Regularization:\", accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZPPceskdrL_",
        "outputId": "1f234b2a-2a54-4048-f46e-c0b71b0d4f66"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy with Elastic Net Regularization: 0.9649122807017544\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 5 :   Write a Python program to train a Logistic Regression model for multiclass classification using multi_class='ovr"
      ],
      "metadata": {
        "id": "Pq8EeKVdiovW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target  # 3 classes: 0, 1, 2\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Logistic Regression with One-vs-Rest strategy\n",
        "model = LogisticRegression(multi_class='ovr', solver='liblinear', max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Prediction\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Accuracy\n",
        "print(\"Multiclass (OvR) Logistic Regression Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RdKnjmiqd1Qh",
        "outputId": "3aa648f6-d018-4322-d70f-c99526f28bc7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Multiclass (OvR) Logistic Regression Accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 6 :  Write a Python program to apply GridSearchCV to tune the hyperparameters (C and penalty) of Logistic Regression. Print the best parameters and accuracy"
      ],
      "metadata": {
        "id": "bayQAKlCioyb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define parameter grid\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10, 100],\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'solver': ['liblinear']  # 'liblinear' supports both l1 and l2\n",
        "}\n",
        "\n",
        "# GridSearchCV\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Best model\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# Output\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "print(\"Test Accuracy with Best Parameters:\", accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acjoGtYJd3fv",
        "outputId": "13a6ba70-bde0-426a-dd12-9b9c15fa22f1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'C': 100, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "Test Accuracy with Best Parameters: 0.9824561403508771\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 7 : Write a Python program to evaluate Logistic Regression using Stratified K-Fold Cross-Validation. Print the average accuracy"
      ],
      "metadata": {
        "id": "LPSwmplvio1X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "import numpy as np\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Define model\n",
        "model = LogisticRegression(max_iter=1000, solver='liblinear')\n",
        "\n",
        "# Stratified K-Fold Cross-Validation\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "scores = cross_val_score(model, X, y, cv=skf, scoring='accuracy')\n",
        "\n",
        "# Output\n",
        "print(\"Cross-Validation Accuracies:\", scores)\n",
        "print(\"Average Accuracy:\", np.mean(scores))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53oNDqFSeR6g",
        "outputId": "09d66be4-1caf-4e60-b740-ff2c1c954772"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-Validation Accuracies: [0.94736842 0.92105263 0.95614035 0.96491228 0.96460177]\n",
            "Average Accuracy: 0.9508150908244062\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 8 :   Write a Python program to load a dataset from a CSV file, apply Logistic Regression, and evaluate its accuracy."
      ],
      "metadata": {
        "id": "rpAuyC2Xio4m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load CSV file\n",
        "df = pd.read_csv(\"data.csv\")  # Replace with your actual CSV file name\n",
        "\n",
        "# Separate features and target (assuming last column is the target)\n",
        "X = df.iloc[:, :-1]\n",
        "y = df.iloc[:, -1]\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Logistic Regression\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"Model Accuracy on CSV Data:\", accuracy)\n"
      ],
      "metadata": {
        "id": "yopqO97QeYNG"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 9 :  Write a Python program to apply RandomizedSearchCV for tuning hyperparameters (C, penalty, solver) in Logistic Regression. Print the best parameters and accuracy"
      ],
      "metadata": {
        "id": "sDJkBA4yio7T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define model\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "\n",
        "# Define hyperparameter space (compatible combinations)\n",
        "param_dist = {\n",
        "    'C': np.logspace(-3, 2, 10),              # Range from 0.001 to 100\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'solver': ['liblinear', 'saga']\n",
        "}\n",
        "\n",
        "# Randomized Search\n",
        "random_search = RandomizedSearchCV(model, param_distributions=param_dist, n_iter=10, cv=5, scoring='accuracy', random_state=42)\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Best estimator prediction\n",
        "best_model = random_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# Output\n",
        "print(\"Best Parameters:\", random_search.best_params_)\n",
        "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIuhnvl-ewXV",
        "outputId": "3f52b70b-d977-4391-b1cd-19699868ac77"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': np.float64(2.1544346900318843)}\n",
            "Test Accuracy: 0.956140350877193\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 10 :  Write a Python program to implement One-vs-One (OvO) Multiclass Logistic Regression and print accuracy"
      ],
      "metadata": {
        "id": "diCrlGRrio-W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.multiclass import OneVsOneClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target  # Multiclass: 0, 1, 2\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# One-vs-One Multiclass Logistic Regression\n",
        "base_model = LogisticRegression(max_iter=1000)\n",
        "ovo_model = OneVsOneClassifier(base_model)\n",
        "ovo_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = ovo_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"One-vs-One Multiclass Logistic Regression Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TnmYyQuDe707",
        "outputId": "2ea48072-2887-466e-d9c1-459eea595d0c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "One-vs-One Multiclass Logistic Regression Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 11 :   Write a Python program to train a Logistic Regression model and visualize the confusion matrix for binary classification"
      ],
      "metadata": {
        "id": "iSS7xNUdipBa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Logistic Regression\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)\n",
        "disp.plot(cmap='Blues')\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "id": "g4ErmuXlfCWj",
        "outputId": "cd57f46d-cca1-4c81-9a81-cd8a62e0d4b4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 12 :  Write a Python program to train a Logistic Regression model and evaluate its performance using Precision, Recall, and F1-Score"
      ],
      "metadata": {
        "id": "tyYesO_WipEE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# Load sample dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train Logistic Regression model\n",
        "model = LogisticRegression(max_iter=10000)  # increased max_iter to ensure convergence\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate Precision, Recall, and F1-Score\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall:    {recall:.4f}\")\n",
        "print(f\"F1-Score:  {f1:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hscbCPxfSLA",
        "outputId": "10b95738-984f-457a-a268-f4905e5eaed2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.9459\n",
            "Recall:    0.9859\n",
            "F1-Score:  0.9655\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 13 :  Write a Python program to train a Logistic Regression model on imbalanced data and apply class weights to improve model performance"
      ],
      "metadata": {
        "id": "_JZ3iT7yipKK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Create an imbalanced dataset\n",
        "X, y = make_classification(\n",
        "    n_samples=1000,\n",
        "    n_features=20,\n",
        "    n_classes=2,\n",
        "    weights=[0.9, 0.1],  # 90% of class 0, 10% of class 1 (imbalanced)\n",
        "    flip_y=0,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Logistic Regression WITHOUT class weights\n",
        "model_no_weights = LogisticRegression(max_iter=1000, random_state=42)\n",
        "model_no_weights.fit(X_train, y_train)\n",
        "y_pred_no_weights = model_no_weights.predict(X_test)\n",
        "\n",
        "print(\"Classification Report WITHOUT Class Weights:\")\n",
        "print(classification_report(y_test, y_pred_no_weights))\n",
        "\n",
        "# Train Logistic Regression WITH class weights balanced\n",
        "model_with_weights = LogisticRegression(max_iter=1000, class_weight='balanced', random_state=42)\n",
        "model_with_weights.fit(X_train, y_train)\n",
        "y_pred_with_weights = model_with_weights.predict(X_test)\n",
        "\n",
        "print(\"\\nClassification Report WITH Class Weights:\")\n",
        "print(classification_report(y_test, y_pred_with_weights))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ULTgxbufZiE",
        "outputId": "f14ce8c3-73ec-4846-eabb-1b74e3a55ddc"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report WITHOUT Class Weights:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.97      0.96       185\n",
            "           1       0.50      0.40      0.44        15\n",
            "\n",
            "    accuracy                           0.93       200\n",
            "   macro avg       0.73      0.68      0.70       200\n",
            "weighted avg       0.92      0.93      0.92       200\n",
            "\n",
            "\n",
            "Classification Report WITH Class Weights:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.84      0.90       185\n",
            "           1       0.25      0.67      0.36        15\n",
            "\n",
            "    accuracy                           0.82       200\n",
            "   macro avg       0.61      0.75      0.63       200\n",
            "weighted avg       0.91      0.82      0.86       200\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 14 :   Write a Python program to train Logistic Regression on the Titanic dataset, handle missing values, and evaluate performance"
      ],
      "metadata": {
        "id": "iT11KBgDjNak"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Load Titanic dataset\n",
        "titanic = sns.load_dataset('titanic')\n",
        "\n",
        "# Preview dataset\n",
        "#print(titanic.head())\n",
        "\n",
        "# Select features and target\n",
        "features = ['pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embarked']\n",
        "target = 'survived'\n",
        "\n",
        "# Handle missing values\n",
        "# For 'age' fill with median\n",
        "titanic['age'].fillna(titanic['age'].median(), inplace=True)\n",
        "\n",
        "# For 'embarked' fill with mode\n",
        "titanic['embarked'].fillna(titanic['embarked'].mode()[0], inplace=True)\n",
        "\n",
        "# Drop rows with missing 'fare' if any (rare)\n",
        "titanic.dropna(subset=['fare'], inplace=True)\n",
        "\n",
        "# Convert categorical features to numeric using one-hot encoding\n",
        "titanic = pd.get_dummies(titanic, columns=['sex', 'embarked'], drop_first=True)\n",
        "\n",
        "# Define X and y\n",
        "X = titanic[[\n",
        "    'pclass', 'age', 'sibsp', 'parch', 'fare', 'sex_male', 'embarked_Q', 'embarked_S'\n",
        "]]\n",
        "y = titanic[target]\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Train Logistic Regression model\n",
        "model = LogisticRegression(max_iter=1000, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate\n",
        "print(f\"Accuracy:  {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Recall:    {recall_score(y_test, y_pred):.4f}\")\n",
        "print(f\"F1-Score:  {f1_score(y_test, y_pred):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGPDjO-ufl4Z",
        "outputId": "548f97b5-5fff-4714-cbc1-3557f51201ce"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-706a715a1e88>:19: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  titanic['age'].fillna(titanic['age'].median(), inplace=True)\n",
            "<ipython-input-17-706a715a1e88>:22: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  titanic['embarked'].fillna(titanic['embarked'].mode()[0], inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.8101\n",
            "Precision: 0.7857\n",
            "Recall:    0.7432\n",
            "F1-Score:  0.7639\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 15 :   Write a Python program to apply feature scaling (Standardization) before training a Logistic Regression model. Evaluate its accuracy and compare results with and without scaling"
      ],
      "metadata": {
        "id": "CS653fuSjNmP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# --- Without Scaling ---\n",
        "model_no_scaling = LogisticRegression(max_iter=10000, random_state=42)\n",
        "model_no_scaling.fit(X_train, y_train)\n",
        "y_pred_no_scaling = model_no_scaling.predict(X_test)\n",
        "accuracy_no_scaling = accuracy_score(y_test, y_pred_no_scaling)\n",
        "\n",
        "# --- With Standardization ---\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "model_scaled = LogisticRegression(max_iter=10000, random_state=42)\n",
        "model_scaled.fit(X_train_scaled, y_train)\n",
        "y_pred_scaled = model_scaled.predict(X_test_scaled)\n",
        "accuracy_scaled = accuracy_score(y_test, y_pred_scaled)\n",
        "\n",
        "print(f\"Accuracy without scaling: {accuracy_no_scaling:.4f}\")\n",
        "print(f\"Accuracy with standardization: {accuracy_scaled:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYvAl4Yzf4uh",
        "outputId": "45d3d4e7-1346-472f-af78-6a99e5d149a8"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy without scaling: 0.9561\n",
            "Accuracy with standardization: 0.9737\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 16 :  Write a Python program to train Logistic Regression and evaluate its performance using ROC-AUC score"
      ],
      "metadata": {
        "id": "Hz8_cPQDjNpK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Logistic Regression model\n",
        "model = LogisticRegression(max_iter=10000, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict probabilities for the positive class\n",
        "y_probs = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Calculate ROC-AUC score\n",
        "roc_auc = roc_auc_score(y_test, y_probs)\n",
        "\n",
        "print(f\"ROC-AUC Score: {roc_auc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frrzHnFFgACE",
        "outputId": "6b2fb404-b600-46eb-e633-b31185afafdf"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC-AUC Score: 0.9977\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 17 :   Write a Python program to train Logistic Regression using a custom learning rate (C=0.5) and evaluate accuracy"
      ],
      "metadata": {
        "id": "U-TL5SZjjNsB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize Logistic Regression with C=0.5\n",
        "model = LogisticRegression(C=0.5, max_iter=10000, random_state=42)\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on test\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy with C=0.5: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWoWtAAVgMxz",
        "outputId": "b646c501-8854-416e-b7dd-905818f2b4bf"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with C=0.5: 0.9649\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 18 :   Write a Python program to train Logistic Regression and identify important features based on model coefficients"
      ],
      "metadata": {
        "id": "ud5eWCsrjNuf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "feature_names = data.feature_names\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Logistic Regression model\n",
        "model = LogisticRegression(max_iter=10000, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Get coefficients\n",
        "coefficients = model.coef_[0]\n",
        "\n",
        "# Create a DataFrame of features and their coefficients\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'Coefficient': coefficients,\n",
        "    'Absolute Coefficient': np.abs(coefficients)\n",
        "})\n",
        "\n",
        "# Sort features by absolute coefficient value in descending order\n",
        "feature_importance = feature_importance.sort_values(by='Absolute Coefficient', ascending=False)\n",
        "\n",
        "print(\"Feature importance based on Logistic Regression coefficients:\")\n",
        "print(feature_importance[['Feature', 'Coefficient']])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIiLc84egYOo",
        "outputId": "a4c9bd05-83e4-4fbe-fd21-9ab2c0456724"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature importance based on Logistic Regression coefficients:\n",
            "                    Feature  Coefficient\n",
            "26          worst concavity    -1.428595\n",
            "11            texture error     1.370567\n",
            "0               mean radius     1.027437\n",
            "25        worst compactness    -0.772709\n",
            "28           worst symmetry    -0.746894\n",
            "6            mean concavity    -0.532558\n",
            "27     worst concave points    -0.510929\n",
            "21            worst texture    -0.508877\n",
            "2            mean perimeter    -0.362135\n",
            "24         worst smoothness    -0.307731\n",
            "7       mean concave points    -0.283692\n",
            "5          mean compactness    -0.237713\n",
            "8             mean symmetry    -0.226682\n",
            "1              mean texture     0.221451\n",
            "12          perimeter error    -0.181409\n",
            "4           mean smoothness    -0.156235\n",
            "20             worst radius     0.111653\n",
            "29  worst fractal dimension    -0.100944\n",
            "10             radius error    -0.097102\n",
            "13               area error    -0.087196\n",
            "15        compactness error     0.047361\n",
            "16          concavity error    -0.042948\n",
            "9    mean fractal dimension    -0.036494\n",
            "18           symmetry error    -0.034737\n",
            "17     concave points error    -0.032402\n",
            "3                 mean area     0.025467\n",
            "14         smoothness error    -0.022455\n",
            "23               worst area    -0.016857\n",
            "22          worst perimeter    -0.015554\n",
            "19  fractal dimension error     0.011605\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 19 :  Write a Python program to train Logistic Regression and evaluate its performance using Cohen’s Kappa Score"
      ],
      "metadata": {
        "id": "5ZvLa79djNxD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split dataset into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Train Logistic Regression model\n",
        "model = LogisticRegression(max_iter=10000, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate Cohen’s Kappa Score\n",
        "kappa_score = cohen_kappa_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Cohen’s Kappa Score: {kappa_score:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67XGm1o3gglt",
        "outputId": "fb4897d1-4db2-4a95-af5f-29a5bfd0a93f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cohen’s Kappa Score: 0.9053\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 20 :   Write a Python program to train Logistic Regression and visualize the Precision-Recall Curve for binary classification"
      ],
      "metadata": {
        "id": "HXop0bZijNzy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split data into train and test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Logistic Regression\n",
        "model = LogisticRegression(max_iter=10000, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict probabilities for the positive class\n",
        "y_scores = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Calculate precision-recall pairs for different thresholds\n",
        "precision, recall, thresholds = precision_recall_curve(y_test, y_scores)\n",
        "\n",
        "# Calculate average precision score\n",
        "avg_precision = average_precision_score(y_test, y_scores)\n",
        "\n",
        "# Plot Precision-Recall curve\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.plot(recall, precision, label=f'Logistic Regression (AP = {avg_precision:.2f})')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "D4MYxbJIgpPX",
        "outputId": "0c4b4aef-3ab8-42ea-82c8-ab607a62f488"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 21 :   Write a Python program to train Logistic Regression with different solvers (liblinear, saga, lbfgs) and compare their accuracy"
      ],
      "metadata": {
        "id": "6ikK6vmajN2C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "solvers = ['liblinear', 'saga', 'lbfgs']\n",
        "results = {}\n",
        "\n",
        "for solver in solvers:\n",
        "    # Initialize Logistic Regression with given solver\n",
        "    model = LogisticRegression(solver=solver, max_iter=10000, random_state=42)\n",
        "\n",
        "    # Train model\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Predict and calculate accuracy\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    results[solver] = accuracy\n",
        "\n",
        "# Display results\n",
        "print(\"Accuracy scores with different solvers:\")\n",
        "for solver, acc in results.items():\n",
        "    print(f\"{solver}: {acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IO__N0AGgwud",
        "outputId": "16e15b86-720c-431b-b76f-8c66b345bff6"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy scores with different solvers:\n",
            "liblinear: 0.9561\n",
            "saga: 0.9737\n",
            "lbfgs: 0.9561\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 22 :  Write a Python program to train Logistic Regression and evaluate its performance using Matthews Correlation Coefficient (MCC)"
      ],
      "metadata": {
        "id": "eUh2l99_jN4s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Train Logistic Regression model\n",
        "model = LogisticRegression(max_iter=10000, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on test data\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate Matthews Correlation Coefficient\n",
        "mcc = matthews_corrcoef(y_test, y_pred)\n",
        "\n",
        "print(f\"Matthews Correlation Coefficient (MCC): {mcc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUhAO0pcg6u1",
        "outputId": "dd03352a-cf5c-4a6c-d930-bc45dd734b69"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matthews Correlation Coefficient (MCC): 0.9068\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 23 :  Write a Python program to train Logistic Regression on both raw and standardized data. Compare their accuracy to see the impact of feature scaling"
      ],
      "metadata": {
        "id": "lDE5WkhRjiKw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Logistic Regression on raw data\n",
        "model_raw = LogisticRegression(max_iter=10000, random_state=42)\n",
        "model_raw.fit(X_train, y_train)\n",
        "y_pred_raw = model_raw.predict(X_test)\n",
        "accuracy_raw = accuracy_score(y_test, y_pred_raw)\n",
        "\n",
        "# Apply standardization (feature scaling)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train Logistic Regression on standardized data\n",
        "model_scaled = LogisticRegression(max_iter=10000, random_state=42)\n",
        "model_scaled.fit(X_train_scaled, y_train)\n",
        "y_pred_scaled = model_scaled.predict(X_test_scaled)\n",
        "accuracy_scaled = accuracy_score(y_test, y_pred_scaled)\n",
        "\n",
        "# Print accuracy comparison\n",
        "print(f\"Accuracy without scaling: {accuracy_raw:.4f}\")\n",
        "print(f\"Accuracy with standardization: {accuracy_scaled:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5ldZRChhF9O",
        "outputId": "a03b084a-b9b6-4935-e69d-2f0952d7fadd"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy without scaling: 0.9561\n",
            "Accuracy with standardization: 0.9737\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 24 :  Write a Python program to train Logistic Regression and find the optimal C (regularization strength) using cross-validation"
      ],
      "metadata": {
        "id": "-ML9DwuHjiO4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Define logistic regression model\n",
        "model = LogisticRegression(max_iter=10000, random_state=42)\n",
        "\n",
        "# Parameter grid for C (inverse regularization strength)\n",
        "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
        "\n",
        "# Grid search with 5-fold cross-validation\n",
        "grid = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "# Best parameter C\n",
        "print(f\"Optimal C: {grid.best_params_['C']}\")\n",
        "\n",
        "# Evaluate on test set\n",
        "best_model = grid.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "id": "N5NquWY7h_W-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 25:  Write a Python program to train Logistic Regression, save the trained model using joblib, and load it again to make predictions."
      ],
      "metadata": {
        "id": "_IlxhLLJjmtv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Train Logistic Regression model\n",
        "model = LogisticRegression(max_iter=10000, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Save the trained model to a file\n",
        "joblib.dump(model, 'logistic_regression_model.joblib')\n",
        "print(\"Model saved to 'logistic_regression_model.joblib'\")\n",
        "\n",
        "# Load the model from the file\n",
        "loaded_model = joblib.load('logistic_regression_model.joblib')\n",
        "print(\"Model loaded from 'logistic_regression_model.joblib'\")\n",
        "\n",
        "# Use loaded model to make predictions\n",
        "y_pred = loaded_model.predict(X_test)\n",
        "\n",
        "# Evaluate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy of loaded model: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "id": "1b5H38E4iOix",
        "outputId": "bbd9cf4a-f166-4106-dfe2-4bc247a6f6da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to 'logistic_regression_model.joblib'\n",
            "Model loaded from 'logistic_regression_model.joblib'\n",
            "Accuracy of loaded model: 0.9561\n"
          ]
        }
      ]
    }
  ]
}